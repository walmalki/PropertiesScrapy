''' Scrapes approx 3000 properties on Craigslist
and get geo data from details page '''

from gc import callbacks
import os
import scrapy
from scrapy.loader import ItemLoader
from scrapy.crawler import CrawlerProcess
from ..items import CraigslistscrapeItem

# Creating the Class

Class RealestateSpider(scrapy.Spider)

   name = 'realestateSpider'

   start_url = ['https://newyork.craigslist.org/search/rea/']

   try:
      os.remove('results.csv')
   except: OSError:
      pass

   def __init__(self):
      self.lat = ""
      self.lon = ""

   def start_requests(self):
      yield scrapy.Request('https://newyork.craigslist.org/search/rea/', callback=self.parse)

   def parse(self, response):
      all_ads = response.xpath('.//div[@class="result-info"]')

      for ads in all_ads:

      # Get details link
      details_link = ads.xpath('.//li[@class="result-row"]/a/@href').get()

      # Go get geo data
      yield response.follow(url=details_link, callback=self.parse_detail)
      
      # Loader
      loader = ItemLoader(item=PropertiesscrapyItem(),selector=ads,response=response)
      loader.add_xpath("price",".//span[@class='result-price']/text()")
      loader.add_xpath("")

   # Nav next page

   def parse_detail(self, response):
      # Set variable to response lon and latest
      self.lon = response.xpath('//meta[@name="geo.position"]/@content').get().split(';')[0]
      self.lat = response.xpath('//meta[@name="geo.position"]/@content').get().split(';')[1]

# main driver 
if __name__ == __main__:
   # create instance called 'cl' as in "C"raigs "L"ist
   cl = CrawlerProcess(settings={
      "FEEDS": {
         "results.csv": {"format": "CSV"}
      }
   })

   cl.crawl(RealestateSpider)
   cl.start()





